# import libraries
import pandas as pd
import numpy as np
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
import seaborn as sns
# from pyspark.sql.types import IntegerType
# from pyspark.ml.evaluation import MulticlassClassificationEvaluator
# from pyspark.ml import Pipeline
# from pyspark.ml.feature import StringIndexer
# from pyspark.ml.feature import OneHotEncoderEstimator
# from pyspark.ml.feature import StandardScaler
# from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
# from pyspark.ml.classification import RandomForestClassifier
# from pyspark.ml.classification import DecisionTreeClassifier
# from pyspark.ml.feature import Normalizer
# import pingouin as pg



# Create spark session
spark = SparkSession.builder.appName('Analysis').getOrCreate()

# Load excel datasets into pandas dataframes
ref = pd.read_excel('./datasets/reccrime-offence-ref.xlsx')
tables = pd.read_excel('./datasets/prc-pfa-mar2013-onwards-tables-191023.xlsx', sheet_name=None)


# Select the table of interest and create a dataframe
yr_2019_20 = tables['2019-20']
yr_2020_21 = tables['2020-21']
yr_2021_22 = tables['2021-22']
yr_2022_23 = tables['2022-23']
yr_2023_24 = tables['2023-24']


# Convert table  and offence_ref_ps to pyspark dataframe
offence_ref = spark.createDataFrame(ref)
df_2019_20 = spark.createDataFrame(yr_2019_20)
df_2020_21 = spark.createDataFrame(yr_2020_21)
df_2021_22 = spark.createDataFrame(yr_2021_22)
df_2022_23 = spark.createDataFrame(yr_2022_23)
df_2023_24 = spark.createDataFrame(yr_2023_24)


# Create temporary views of the dataframes
df_2019_20.createOrReplaceTempView('df_2019_20')
df_2020_21.createOrReplaceTempView('df_2020_21')
df_2021_22.createOrReplaceTempView('df_2021_22')
df_2022_23.createOrReplaceTempView('df_2022_23')
df_2023_24.createOrReplaceTempView('df_2023_24')

# Write sql queries to join tables
query_1 = """
                SELECT * FROM df_2019_20
                UNION
                SELECT * FROM df_2020_21
                UNION 
                SELECT * FROM df_2021_22
                UNION
                SELECT * FROM df_2022_23
                UNION
                SELECT * FROM df_2023_24
"""

# Load query and return dataframe
offence_df = spark.sql(query_1)


# Rename col to remove white space
rename_cols = {
                'Financial Year': 'Financial_Year',
                'Financial Quarter':'Financial_Quarter',
                'Force Name':'Force_Name',
                'Offence Description':'Offence_Description',
                'Offence Group':'Offence_Group',
                'Offence Subgroup':'Offence_Subgroup',
                'Offence Code':'Offence_Code',
                'Number of Offences':'Number_of_Offences',
                'Old PRC offence group': 'Old_PRC_offence_group',
                'Old offence sub-group': 'Old_offence_sub-group',
                'New ONS offence group': 'New_ONS_offence_group',
                'New ONS sub-offence group': 'New_ONS_sub-offence_group'
}

# Loops through rename_cols and removes white space
for old_name, new_name in rename_cols.items():
    offence_df = offence_df.withColumnRenamed(old_name, new_name)
    offence_ref = offence_ref.withColumnRenamed(old_name, new_name)



# Drop duplicates in offence_ref
offence_ref = offence_ref.dropDuplicates()

# Create temporary views of the dataframes
offence_df.createOrReplaceTempView('offence_df')
offence_ref.createOrReplaceTempView('offence_ref')

# Write sql query to join tables 
query_2 = """
                    SELECT * FROM offence_df
                    INNER JOIN offence_ref 
                    ON offence_df.Offence_Code = offence_ref.Offence_Code;
                """

#  Create offence_final with query
offence_final = spark.sql(query_2)


# Print schema 
offence_final.printSchema()


# Get year from financial year column
offence_final = offence_final.withColumn('Financial_Year', substring('Financial_Year',  1,  4))

# Convert Financial year column to int
offence_final = offence_final.withColumn('Financial_Year',  offence_final.Financial_Year.cast('int'))


offence_final.printSchema()


# Descriptive statistics of  Numeric Column
offence_final.describe(['Number_of_Offences']).show()


# Covariance of FInancial year anf Number of offences


# Covariance of FInancial quarter and Number of offences



# check for skewness of Number of Offences


# Plot of Numver of offences

# Sample the dataframe
offence_sample = offence_final.select('Number_of_Offences').sample(False, 0.50, 42)

# Convert offence sample to pandas
offence_pd = offence_sample.toPandas()

# Plot 
sns.displot(offence_pd);

#Lmplot of Numver of offence and financial year
offence_sample_1 = offence_final.select('Number_of_Offences', 'Financial_Year').sample(False, 0.50, 42)

# Convert to pandas
offence_pd_1 = offence_sample_1.toPandas()

#Plot
sns.lmplot(y='Number_of_Offences', x='Financial_Year', data=offence_pd_1)









